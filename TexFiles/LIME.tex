\section{LIME}
\begin{frame}
	\frametitle{Requirements}
	\begin{Large}
		\textbf{What do we want:}
		\begin{itemize}
			\item Human Readable Model Explanation
			\item For Every Classifier
			\item For Every Input
		\end{itemize}
	~\newline
	\begin{center}
		\textbf{ features $\neq$ human readable }
	\end{center}
	~\newline
	\end{Large}
	To gain $readability$: 
	\begin{itemize}
		\item show influence relative to each other, not as numbers
		\item only show most important features
		\item use \textit{superpixels} instead of pixels
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Definitions}
	Let:
	\begin{enumerate}
		\item $G$ be any possible explanation model
		\item $g$ be our explanation Model
		\item $\Omega(g)$ the complexity of our Model
		\begin{itemize}
			\item Weights in a regressions model
			\item Depth of an decisiontree
			\item Number of trees in a random forest
		\end{itemize}
		\item $f: Features -> Class $ be the real classification
		\item $\Pi_x(z)$ as proximity-measure from $x$ to $z$
		\item $\mathcal{L}(f,g,\Pi_x)$ measure of un-faithfullness of $g$ compared to $f$ given the proxmity $\Pi_x$
	\end{enumerate}
\end{frame}

\begin{frame}
	\frametitle{Minimizing Fidelity $\cdot$ Interpretability}
	\begin{Large}
		Wanted: ~\newline
		\begin{center}
			$\xi(x) = argmin_{g\in G} ~ \mathcal{L}(f,g,\Pi_x) + \Omega(g)$
		\end{center}
		Read: 
		\begin{itemize}
			\item We want for every input $x$
			\item an explanation(-model)
			\item where complexity of $g$ and the failure of $g$ are minimal
			\item given a set of possible explanations $G$
		\end{itemize}
	\end{Large}
~\newline ~\newline 
We do so by picking samples $x^,$ as subsets from an input $x$ and \textbf{optimizing} our model $g$ \footnote{We do not really check different models, we train one} 
\end{frame}

\begin{frame}
	\frametitle{Local Interpretable Model-Agnostic Explanations}
	\framesubtitle{The LIME-Algorithm}
	Additional Requirements: ~\newline 
	\textbf{LASSO}\footnote{Further Reading: \url{https://beta.vu.nl/nl/Images/werkstuk-fonti_tcm235-836234.pdf}} - \textit{Least Absolute Shrinkage and Selection Operator} ~\newline 
	Machine Learning algorithm to select most important features relative to each other. ~\newline
	G are only \textit{sparse linear regression models} (e.g. Decision Trees or simple logistic regression) ~\newline 
	
	\begin{algorithm}[H]
		\SetKwInOut{Require}{Require}
		\Require{Classifier $f$, Number of samples $N$}
		\Require{Instance $x$, and its interpretable version $x^,$}
		\Require{Similarity kernel $\pi_x$, Length of explanation $K$}
		$\mathcal{Z} \leftarrow \{\}$\;
		\ForEach{$i \in \{1,2,..,N\}$}{
		$z^,_i \leftarrow sample\_around(x^,)$\;
		$\mathcal{Z} \leftarrow \mathcal{Z} \cup \<z^,_i ,f(z_i,\pi_x(z_i)) \>$\;
		}
		$ w \leftarrow K-Lasso(\mathcal{Z},K)  \triangleright~ with~ z^,_i~ as~ features,~ f(z) ~ as ~ target$\;
		return  $w$\;
	\end{algorithm}

\end{frame}